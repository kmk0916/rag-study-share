{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. keyword 사전 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용자의 질문을 vector database에 적합한 질문으로 변경해보자\n",
    "- 1~4까지는 2. LangChain을 활용한 Vector Database 구성 (Pinecone + Upstage) 과 동일\n",
    "- 5에서 qa_chain으로 llm에 답변 구하는 부분 제거\n",
    "- 6에서 사용자의 질문을 변경하는 chain을 생성하여 기존의 qa_chain과 연결하고, llm에 질문함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.20\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting langchain-openai==0.1.8\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "Collecting langchain-upstage==0.5.0\n",
      "  Using cached langchain_upstage-0.5.0-py3-none-any.whl (20 kB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached sqlalchemy-2.0.44-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.13.1-cp311-cp311-win_amd64.whl (454 kB)\n",
      "     -------------------------------------- 454.8/454.8 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 8.6 MB/s eta 0:00:00\n",
      "Collecting langchain-core<0.2.0,>=0.1.52\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "     -------------------------------------- 303.1/303.1 kB 6.2 MB/s eta 0:00:00\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "     -------------------------------------- 311.8/311.8 kB 9.4 MB/s eta 0:00:00\n",
      "Collecting numpy<2,>=1\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 9.6 MB/s eta 0:00:00\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "     -------------------------------------- 462.4/462.4 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2\n",
      "  Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "The conflict is caused by:\n",
      "    langchain 0.1.20 depends on langchain-core<0.2.0 and >=0.1.52\n",
      "    langchain-openai 0.1.8 depends on langchain-core<0.3 and >=0.2.2\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install langchain-openai==0.1.8 and langchain==0.1.20 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv langchain langchain-upstage==0.5.0 langchain-community langchain-text-splitters docx2txt \n",
    "%pip install langchain-pinecone\n",
    "%pip install \"langchain==0.1.20\" \"langchain-openai==0.1.8\" \"langchain-upstage==0.5.0\" --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 지식 저장소(Knowledge Base) 구성을 위한 데이터 생성\n",
    "- AI가 tax_with_markdown.docx라는 문서를 참고하여 대답할 수 있도록, <br/>\n",
    "  tax_with_markdown.docx 문서 내의 내용을 가지고 Vector Database를 구성해야 합니다.<br/>\n",
    "  아래 코드는 tax_with_markdown.docx를 Vector Database에 저장하기 전 적당한 크기로 나누는 작업(chunking)을 하는 코드입니다.\n",
    "\n",
    "- [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/)를 활용한 데이터 나누기(chunking)\n",
    "    - split 된 데이터 chunk를 Large Language Model(LLM)에게 전달하면 토큰 절약 가능\n",
    "    - 비용 감소와 답변 생성시간 감소의 효과\n",
    "    - LangChain에서 다양한 [TextSplitter](https://python.langchain.com/v0.2/docs/how_to/#text-splitters)들을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# AI가 학습할 원본 자료를 읽는 단계(tax_with_markdown.docx 파일을 불러옵니다.)\n",
    "loader = Docx2txtLoader('./tax_with_markdown.docx')\n",
    "\n",
    "# 문서의 내용을 AI가 다루기 쉽도록 적당한 크기로 나누는 작업(chunking)을 수행합니다.\n",
    "# 이 때, 어떻게 나눌지를 text_splitter를 통해 전달합니다.\n",
    "# - `chunk_size` 는 split 된 chunk의 최대 크기\n",
    "# - `chunk_overlap`은 앞 뒤로 나뉘어진 chunk들이 얼마나 겹쳐도 되는지 지정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞에서 잘게 나눈 문서를 실제로 AI가 이해할 수 있는 형태로 저장하는 단계 \n",
    "- AI는 텍스트를 그대로 저장되거나 검색하지 않기 때문에,<br/>\n",
    "잘게 나눈 문서들을 임베딩하여 저장합니다.\n",
    "- 임베딩하는 방법에는 다양한 모델이 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azasu\\Desktop\\inflearn-llm-application\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  8%|▊         | 1/12 [00:06<01:13,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 0~20 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:10<00:51,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 20~40 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:14<00:42,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 40~60 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:21<00:42,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 60~80 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:25<00:34,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 80~100 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:29<00:28,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 100~120 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:35<00:25,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 120~140 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [00:39<00:18,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 140~160 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:44<00:14,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 160~180 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:48<00:09,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 180~200 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:53<00:04,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 200~220 업로드 성공\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:55<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 배치 220~240 업로드 성공\n",
      "✅ 모든 문서 업로드 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 환경변수를 불러오기\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Upstage에서 제공하는 'solar-embedding-1-large' 모델을 사용\n",
    "# → 문서의 내용을 숫자로 표현(벡터화)하여 유사한 의미끼리 비교할 수 있게 함\n",
    "embedding = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# 3. index_name은 Pinecone 안에서 데이터를 구분하는 이름\n",
    "# → 여러 개의 프로젝트나 주제를 각각의 index로 나누어 관리할 수 있음\n",
    "index_name = 'tax-markdown-index'\n",
    "\n",
    "# 4. PineconeVectorStore 인스턴스를 생성\n",
    "# → 나중에 여기에 벡터화된 문서를 업로드하고 검색할 수 있음\n",
    "database = PineconeVectorStore(index_name=index_name, embedding=embedding)\n",
    "\n",
    "# Pinecone은 한 번에 너무 큰 데이터를 업로드하면 에러가 날 수 있음 (4MB 제한)\n",
    "# 5. 따라서 문서를 20개씩 나누어 업로드\n",
    "\n",
    "batch_size = 20  # 너무 크면 에러 발생, 10~50 정도가 안전\n",
    "\n",
    "for i in tqdm(range(0, len(document_list), batch_size)):\n",
    "    batch = document_list[i:i+batch_size]\n",
    "    try:\n",
    "        database.add_documents(batch)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 배치 {i}~{i+batch_size} 업로드 실패: {e}\")\n",
    "    else:\n",
    "        print(f\"✅ 배치 {i}~{i+batch_size} 업로드 성공\")\n",
    "\n",
    "print(\"✅ 모든 문서 업로드 완료!\")\n",
    "\n",
    "# 여기까지 완료하였다면, AI가 참고할 database가 생성된 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 답변 생성을 위한 Retrieval\n",
    "- `Pinecone`에 저장한 데이터를 유사도 검색(`similarity_search()`)를 활용해서 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자가 궁금한 질문\n",
    "query = '연봉 5천만원인 직장인의 소득세는 얼마인가요?'\n",
    "\n",
    "# Pinecone에 저장된 벡터 데이터에서 유사도 기반으로 관련 문서 검색\n",
    "# k=2 → 가장 관련성이 높은 2개의 문서 조각을 가져옴\n",
    "retrieved_docs = database.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9f50042e-125d-4b22-87a3-871b2fba5e44', metadata={'source': './tax_with_markdown.docx'}, page_content='제55조(세율) ①거주자의 종합소득에 대한 소득세는 해당 연도의 종합소득과세표준에 다음의 세율을 적용하여 계산한 금액(이하 “종합소득산출세액”이라 한다)을 그 세액으로 한다. <개정 2014. 1. 1., 2016. 12. 20., 2017. 12. 19., 2020. 12. 29., 2022. 12. 31.>\\n\\n| 종합소득 과세표준          | 세율                                         |\\n\\n|-------------------|--------------------------------------------|\\n\\n| 1,400만원 이하     | 과세표준의 6퍼센트                             |\\n\\n| 1,400만원 초과     5,000만원 이하     | 84만원 + (1,400만원을 초과하는 금액의 15퍼센트)  |\\n\\n| 5,000만원 초과   8,800만원 이하     | 624만원 + (5,000만원을 초과하는 금액의 24퍼센트) |\\n\\n| 8,800만원 초과 1억5천만원 이하    | 3,706만원 + (8,800만원을 초과하는 금액의 35퍼센트)|\\n\\n| 1억5천만원 초과 3억원 이하         | 3,706만원 + (1억5천만원을 초과하는 금액의 38퍼센트)|\\n\\n| 3억원 초과    5억원 이하         | 9,406만원 + (3억원을 초과하는 금액의 38퍼센트)   |\\n\\n| 5억원 초과      10억원 이하        | 1억 7,406만원 + (5억원을 초과하는 금액의 42퍼센트)|\\n\\n| 10억원 초과        | 3억 8,406만원 + (10억원을 초과하는 금액의 45퍼센트)|\\n\\n\\n\\n\\n\\n② 거주자의 퇴직소득에 대한 소득세는 다음 각 호의 순서에 따라 계산한 금액(이하 “퇴직소득 산출세액”이라 한다)으로 한다.<개정 2013. 1. 1., 2014. 12. 23.>\\n\\n1. 해당 과세기간의 퇴직소득과세표준에 제1항의 세율을 적용하여 계산한 금액\\n\\n2. 제1호의 금액을 12로 나눈 금액에 근속연수를 곱한 금액\\n\\n3. 삭제<2014. 12. 23.>\\n\\n[전문개정 2009. 12. 31.]\\n\\n\\n\\n제2관 세액공제 <개정 2009. 12. 31.>\\n\\n\\n\\n제56조(배당세액공제) ① 거주자의 종합소득금액에 제17조제3항 각 호 외의 부분 단서가 적용되는 배당소득금액이 합산되어 있는 경우에는 같은 항 각 호 외의 부분 단서에 따라 해당 과세기간의 총수입금액에 더한 금액에 해당하는 금액을 종합소득 산출세액에서 공제한다. <개정 2009. 12. 31.>\\n\\n② 제1항에 따른 공제를 “배당세액공제”라 한다.<개정 2009. 12. 31.>\\n\\n③ 삭제<2003. 12. 30.>\\n\\n④ 제1항을 적용할 때 배당세액공제의 대상이 되는 배당소득금액은 제14조제2항의 종합소득과세표준에 포함된 배당소득금액으로서 이자소득등의 종합과세기준금액을 초과하는 것으로 한다.<개정 2009. 12. 31.>\\n\\n⑤ 삭제<2006. 12. 30.>'),\n",
       " Document(id='43184527-c76d-421c-b598-77033f8ccb1e', metadata={'source': './tax_with_markdown.docx'}, page_content='제55조(세율) ①거주자의 종합소득에 대한 소득세는 해당 연도의 종합소득과세표준에 다음의 세율을 적용하여 계산한 금액(이하 “종합소득산출세액”이라 한다)을 그 세액으로 한다. <개정 2014. 1. 1., 2016. 12. 20., 2017. 12. 19., 2020. 12. 29., 2022. 12. 31.>\\n\\n| 종합소득 과세표준          | 세율                                         |\\n\\n|-------------------|--------------------------------------------|\\n\\n| 1,400만원 이하     | 과세표준의 6퍼센트                             |\\n\\n| 1,400만원 초과     5,000만원 이하     | 84만원 + (1,400만원을 초과하는 금액의 15퍼센트)  |\\n\\n| 5,000만원 초과   8,800만원 이하     | 624만원 + (5,000만원을 초과하는 금액의 24퍼센트) |\\n\\n| 8,800만원 초과 1억5천만원 이하    | 3,706만원 + (8,800만원을 초과하는 금액의 35퍼센트)|\\n\\n| 1억5천만원 초과 3억원 이하         | 3,706만원 + (1억5천만원을 초과하는 금액의 38퍼센트)|\\n\\n| 3억원 초과    5억원 이하         | 9,406만원 + (3억원을 초과하는 금액의 38퍼센트)   |\\n\\n| 5억원 초과      10억원 이하        | 1억 7,406만원 + (5억원을 초과하는 금액의 42퍼센트)|\\n\\n| 10억원 초과        | 3억 8,406만원 + (10억원을 초과하는 금액의 45퍼센트)|\\n\\n\\n\\n\\n\\n② 거주자의 퇴직소득에 대한 소득세는 다음 각 호의 순서에 따라 계산한 금액(이하 “퇴직소득 산출세액”이라 한다)으로 한다.<개정 2013. 1. 1., 2014. 12. 23.>\\n\\n1. 해당 과세기간의 퇴직소득과세표준에 제1항의 세율을 적용하여 계산한 금액\\n\\n2. 제1호의 금액을 12로 나눈 금액에 근속연수를 곱한 금액\\n\\n3. 삭제<2014. 12. 23.>\\n\\n[전문개정 2009. 12. 31.]\\n\\n\\n\\n제2관 세액공제 <개정 2009. 12. 31.>\\n\\n\\n\\n제56조(배당세액공제) ① 거주자의 종합소득금액에 제17조제3항 각 호 외의 부분 단서가 적용되는 배당소득금액이 합산되어 있는 경우에는 같은 항 각 호 외의 부분 단서에 따라 해당 과세기간의 총수입금액에 더한 금액에 해당하는 금액을 종합소득 산출세액에서 공제한다. <개정 2009. 12. 31.>\\n\\n② 제1항에 따른 공제를 “배당세액공제”라 한다.<개정 2009. 12. 31.>\\n\\n③ 삭제<2003. 12. 30.>\\n\\n④ 제1항을 적용할 때 배당세액공제의 대상이 되는 배당소득금액은 제14조제2항의 종합소득과세표준에 포함된 배당소득금액으로서 이자소득등의 종합과세기준금액을 초과하는 것으로 한다.<개정 2009. 12. 31.>\\n\\n⑤ 삭제<2006. 12. 30.>')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieved_docs에는 검색된 문서 조각들이 리스트 형태로 저장됨\n",
    "# 이 문서 조각들을 LLM에 전달하면, 질문에 맞는 답변을 생성할 수 있음\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Augmentation을 위한 Prompt 활용\n",
    "- Retrieval된 문서를 기반으로 LLM이 답변을 생성하도록 “질문과 문서를 조합하는 프롬프트(Prompt)”를 준비하는 단계\n",
    "- Retrieval된 데이터는 LangChain에서 제공하는 프롬프트(`\"rlm/rag-prompt\"`) 사용\n",
    "- prompt: AI에게 'retrieved_docs를 참고해서 질문에 답해라'라는 지시를 전달하는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# ChatUpstage: Upstage의 대화형 LLM 모델 불러오기\n",
    "# → 이후 Retrieval된 문서와 결합해서 답변 생성 가능\n",
    "llm = ChatUpstage() # LLM 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# LangChain Hub를 통해 미리 만들어진 프롬프트를 가져오기\n",
    "# → \"rlm/rag-prompt\"는 RAG(Retrieval-Augmented Generation)에 맞게 설계된 프롬프트\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 답변 생성 (실제로 AI가 답변을 만드는 단계)\n",
    "\n",
    "- LangChain에서는 RetrievalQA 라는 도구를 사용해서 지금까지 생성한 LLM + Retrieval된 문서 + Prompt를 결합할 수 있음\n",
    "- [RetrievalQA](https://docs.smith.langchain.com/old/cookbook/hub-examples/retrieval-qa-chain)를 통해 LLM에 전달\n",
    "    - `RetrievalQA`는 [create_retrieval_chain](https://python.langchain.com/v0.2/docs/how_to/qa_sources/#using-create_retrieval_chain)으로 대체됨\n",
    "    - 실제 ChatBot 구현 시 `create_retrieval_chain`으로 변경하는 과정을 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azasu\\AppData\\Local\\Temp\\ipykernel_19504\\1822491604.py:10: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  ai_message = qa_chain({\"query\": query})\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# RetrievalQA: LLM + Retrieval + Prompt를 결합해 답변을 만드는 LangChain 도구\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    retriever=database.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Retrieval을 위한 keyword 사전 활용\n",
    "\n",
    "- Knowledge Base에서 사용되는 keyword를 활용하여 질문할 수 있도록 사용자 질문 수정<br/>\n",
    " ex) 사용자 질문(query)의 직장인을 거주자로 변경하는 chain 추가해보자\n",
    "- LangChain Expression Language (LCEL)을 활용한 Chain 연계 <- 체인끼리 쉽게 연결하도록 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 변환 사전 정의\n",
    "# Knowledge Base에 맞게 질문을 바꾸기 위한 규칙\n",
    "dictionary = [\"사람을 나타내는 표현 -> 거주자\"]\n",
    "\n",
    "# prompt 생성\n",
    "prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "    사용자의 질문을 보고, 우리의 사전을 참고해서 사용자의 질문을 변경해주세요.\n",
    "    만약 변경할 필요가 없다고 판단된다면, 사용자의 질문을 변경하지 않아도 됩니다.\n",
    "    그런 경우에는 질문만 리턴해주세요\n",
    "    사전: {dictionary}\n",
    "    \n",
    "    질문: {{question}}\n",
    "\"\"\")\n",
    "\n",
    "# Chain 구성\n",
    "dictionary_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 기존 qa_chain과 연결하여, 변환된 질문으로 답변 생성 가능\n",
    "tax_chain = {\"query\": dictionary_chain} | qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 변환\n",
    "new_question = dictionary_chain.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'질문: 연봉 5천만원인 거주자의 종합소득세는 얼마인가요?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 질문으로 실제 답변 생성\n",
    "ai_response = tax_chain.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '질문: 연봉 5천만원인 거주자의 종합소득세는 얼마인가요?',\n",
       " 'result': '연봉 5천만원인 거주자의 종합소득세는 547만원입니다. (산출세액 547만원 - 세액공제 0만원 = 결정세액 547만원)'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-llm-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
